{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"llmware/bling-1.4b-0.1\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"llmware/bling-1.4b-0.1\")  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"main-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://deltek.com/en\",\"https://www.deltek.com/en/about/contact-us\", \"https://www.deltek.com/en/small-business\"),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "all_splits_text = [split.page_content for split in all_splits]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "doc_embeddings = SentenceTransformer('all-MiniLM-L6-v2').encode(all_splits_text)\n",
    "query = \"Give me 3 different reasons Why is deltek liked by customers?\"\n",
    "query_embeddings = SentenceTransformer('all-MiniLM-L6-v2').encode(query)\n",
    "print(doc_embeddings.shape)\n",
    "pairs = zip(all_splits_text, doc_embeddings)\n",
    "\n",
    "vectorstore = FAISS.from_embeddings(pairs, SentenceTransformer('all-MiniLM-L6-v2'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "results = cosine_similarity(doc_embeddings, query_embeddings.reshape(1,-1)).reshape((-1,))\n",
    "k = 4\n",
    "ixs = results.argsort()\n",
    "ixs = ixs[::-1]\n",
    "\n",
    "relevant_docs = []\n",
    "results2 = []\n",
    "for i in ixs:\n",
    "    relevant_docs.append(all_splits[i].page_content)\n",
    "    results2.append(results[i])\n",
    "relevant_docs = relevant_docs[:k]\n",
    "formatted_docs = \"\\n\\n\".join(doc for doc in relevant_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = formatted_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = {\"context\": context, \n",
    "          \"query\":query}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prompt = \"<human>: \" + entries[\"context\"] + \"\\n\" + entries[\"query\"] + \"\\n\" + \"<bot>:\"\n",
    "\n",
    "inputs = tokenizer(new_prompt, return_tensors=\"pt\")  \n",
    "start_of_output = len(inputs.input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(\n",
    "        inputs.input_ids.to(\"cpu\"),\n",
    "        attention_mask=inputs.attention_mask.to(\"cpu\"),\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        do_sample=True,\n",
    "        temperature=0.3,\n",
    "        max_new_tokens=100,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " •Customer satisfaction: Deltek's solutions are the preferred choice for small businesses to help fuel business growth.\n",
      "•Customer satisfaction: Deltek's solutions are the preferred choice for small businesses to help fuel business growth.\n",
      "•Customer satisfaction: Deltek's solutions are the preferred choice for small businesses to help fuel business growth.\n"
     ]
    }
   ],
   "source": [
    "output_text = tokenizer.decode(outputs[0][start_of_output:], skip_special_tokens=True)\n",
    "print(output_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
