{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "question_answerer = pipeline(\"question-answering\", model='distilbert-base-uncased-distilled-squad')\n",
    "pipe = pipeline(\"text-generation\", model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "\n",
    "##open source embedding model\n",
    "# model_name = \"BAAI/bge-large-en-v1.5\"\n",
    "# model_kwargs = {'device': 'cpu'}\n",
    "# encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
    "\n",
    "# embeddings = HuggingFaceBgeEmbeddings(\n",
    "#     model_name=model_name,\n",
    "#     model_kwargs=model_kwargs,\n",
    "#     encode_kwargs=encode_kwargs,\n",
    "#     query_instruction= 'Generate a representation for this sentence that can be used to retrieve related sentences:'\n",
    "# )\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"main-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://deltek.com/en\",\"https://www.deltek.com/en/about/contact-us\", \"https://www.deltek.com/en/small-business\", \"https://www.deltek.com/en/customers\",\n",
    "            \"https://www.deltek.com/en/support\", \"https://www.deltek.com/en/partners\"),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "all_splits_text = [split.page_content for split in all_splits]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDocs(query, all_splits, embeddings):\n",
    "    db = FAISS.from_documents(all_splits, embeddings)\n",
    "\n",
    "    ##get relevant docs from vectorstore\n",
    "    relevant_docs = db.similarity_search(query, k = 5)\n",
    "    formatted_docs = '\\n'.join(doc.page_content for doc in relevant_docs)\n",
    "    return formatted_docs\n",
    "\n",
    "def getoutput(query, context):\n",
    "    result = question_answerer(question= query, context=context)\n",
    "    return result['answer']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDocsfaster(query, all_splits_text, model):\n",
    "    doc_embeddings = model.encode(all_splits_text)\n",
    "    query_embeddings = model.encode(query)\n",
    "    results = cosine_similarity(doc_embeddings, query_embeddings.reshape(1,-1)).reshape((-1,))\n",
    "    ixs = results.argsort()\n",
    "    ixs = ixs[::-1]\n",
    "    relevant_docs = []\n",
    "\n",
    "    for i in ixs:\n",
    "        relevant_docs.append(all_splits[i].page_content)\n",
    "    formatted_docs = \"\\n\\n\".join(doc for doc in relevant_docs)\n",
    "    return formatted_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class userinput(BaseModel):\n",
    "    input: str\n",
    "class response(BaseModel):\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_something(query: userinput):\n",
    "    query = query.input\n",
    "    context = getDocsfaster(query, all_splits_text, model)\n",
    "    output = getoutput(query, context)\n",
    "    response.answer = output\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "i1 = userinput(input = \"What is Deltek?\")\n",
    "query = i1.input\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = generate_something(i1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "industry-specific expertise\n"
     ]
    }
   ],
   "source": [
    "print(out.answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
